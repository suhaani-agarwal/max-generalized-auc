library(ggplot2)
library(data.table)
library(batchtools)
library(aum)
library(dplyr)
library(purrr)

(testFold.vec <- Sys.glob("../neuroblastoma-data/data/*/cv/*/testFolds/*"))
testFold.path <- "../neuroblastoma-data/data/H3K27ac-H3K4me3_TDHAM_BP/cv/equal_labels/testFolds/3"
seed <- 1
init.name="IntervalRegressionCV"
aum.type="count"
OneBatch <- function(testFold.path, aum.type, init.name, seed){
  library(data.table)
  cv.path <- dirname(dirname(testFold.path))
  folds.csv <- file.path(cv.path, "folds.csv")
  cv.type <- basename(cv.path)
  test.fold <- basename(testFold.path)
  data.dir <- dirname(dirname(cv.path))
  data.name <- basename(data.dir)
  data.list <- list()
  for(f in c("inputs", "outputs", "evaluation")){
    f.csv.xz <- file.path(data.dir, paste0(f, ".csv.xz"))
    if(file.exists(f.csv.xz)){
      system(paste("unxz", f.csv.xz))
    }
    f.csv <- file.path(data.dir, paste0(f, ".csv"))
    f.dt <- data.table::fread(f.csv)
    data.list[[f]] <- f.dt
  }
  ## replace positive fn at end with 0 to avoid AUM=Inf.
  data.list$evaluation[, `:=`(
    min.fn=min(fn),
    max.fp=max(fp),
    min.lambda = exp(min.log.lambda),
    example=sequenceID
  ), by=sequenceID]
  bad <- data.list$evaluation[min.log.lambda == -Inf & min.fn < fn]
  if(nrow(bad)){
    print(bad)
  }
  data.list$evaluation[min.log.lambda == -Inf & 0 < fn]
  ## code below not necessary since this does not happen in our real
  ## data sets, but it could theoretically in some data.
  data.list$aum.input <- data.table(data.list$evaluation)[, `:=`(
    possible.fn=possible.fn-min.fn,
    fn=fn-min.fn,
    possible.fp=max.fp
  ), by=sequenceID]
  ## read folds.  
  folds.dt <- data.table::fread(folds.csv)
  folds.dt[fold == test.fold, set := "test"]
  folds.dt[fold != test.fold, set := rep(
    c("subtrain", "validation"), l=.N)]
  folds.dt[, table(fold, set)]
  X.all <- scale(data.list$inputs[, -1])#rm seqID.
  rownames(X.all) <- data.list$inputs$sequenceID
  X.finite <- X.all[, apply(is.finite(X.all), 2, all)]
  set.vec <- folds.dt[rownames(X.finite), set, on="sequenceID"]
  seqs.list <- list()
  diffs.list <- list()
  aum.vec.list <- list()
  for(s in unique(folds.dt$set)){
    seqs.set <- folds.dt[s==set, sequenceID]
    seqs.list[[s]] <- seqs.set
    seqs.diff <- aum::aum_diffs_penalty(
      data.list$evaluation,
      seqs.set,
      denominator=aum.type)
    diffs.list[[s]] <- seqs.diff
  }
  totals <- colSums(diffs.list$subtrain[, .(fp_diff, fn_diff)])
  X.subtrain <- X.finite[set.vec=="subtrain",]
  neg.t.X.subtrain <- -t(X.subtrain)
  seqs.train <- with(seqs.list, c(subtrain, validation))
  y.train <- data.list[["outputs"]][
    seqs.train,
    cbind(min.log.lambda, max.log.lambda),
    on="sequenceID"]
  keep <- apply(is.finite(y.train), 1, any)
  X.train <- X.finite[seqs.train, ]
  N.param <- ncol(X.finite)+1
  init.param <- structure(
    rep(0, N.param),
    names=c("(Intercept)",colnames(X.finite)))
  init.fun.list <- list(
    IntervalRegressionCV=function(){
      fit <- penaltyLearning::IntervalRegressionCV(
        X.train[keep, ],
        y.train[keep, ])
      some.param <- fit[["param.mat"]]
      init.param[names(some.param)] <- some.param
      init.param
    },
    zero=function(){
      init.param+rnorm(N.param)
    }
  )
  iteration.dt.list <- list()
  considered.dt.list <- list()
  obj.sign.list <- list(aum=1)#list(auc=-1, aum=1)
  for(seed in seeds)for(init.name in names(init.fun.list)){
    init.fun <- init.fun.list[[init.name]]
    set.seed(seed)
    int.weights <- init.fun()
    for(algo in c("grid","exactL","exactQ","hybrid"))for(objective in names(obj.sign.list)){
      start.time <- microbenchmark::get_nanotime()
      computeROC <- function(w, i, set){
        pred.pen.vec <- (X.finite %*% w) + i
        pred.dt <- data.table(
          sequenceID=rownames(pred.pen.vec),
          pred.log.lambda=-as.numeric(pred.pen.vec))
        is.set <- set.vec==set
        set.dt <- pred.dt[is.set]
        L <- penaltyLearning::ROChange(
          data.list$evaluation, set.dt, "sequenceID")
        alist <- aum_auc(diffs.list[[set]], pred.pen.vec[ seqs.list[[set]], ])
        L$aum.diffs <- alist$aum
        L$auc.diffs <- alist$auc
        L
      }
      aum_auc <- function(diffs.dt, pred.vec){
        aum.list <- aum::aum(diffs.dt, pred.vec)
        before.dt <- data.table(aum.list$total_error, key="thresh")[, `:=`(
          TPR_before=1-fn_before/-totals[["fn_diff"]],
          FPR_before=fp_before/totals[["fp_diff"]])]
        aum.list$auc <- before.dt[, .(
          FPR=c(FPR_before, 1),
          TPR=c(TPR_before, 1)
        )][, sum((FPR[-1]-FPR[-.N])*(TPR[-1]+TPR[-.N])/2)]
        aum.list
      }
      obj.sign <- obj.sign.list[[objective]]
      weight.vec <- int.weights[-1]
      intercept <- int.weights[1]
      prev.obj <- Inf*obj.sign
      step.number <- 0
      elapsed.time <- 0
      max.iterations <- if (algo == "exactQ") {
        nrow(diffs.list$subtrain) * (nrow(diffs.list$subtrain)) - 1 / 2
      } else {
        nrow(diffs.list$subtrain)
      }
      while({
        summary.dt.list <- list()
        for(set in names(seqs.list)){
          set.PL <- computeROC(weight.vec, intercept, set)
          summary.dt.list[[set]] <- with(set.PL, data.table(
            set,
            thresholds[threshold=="predicted"],
            auc, aum, auc.diffs, aum.diffs))
        }
        summary.dt <- do.call(rbind, summary.dt.list)
        current.time <- microbenchmark::get_nanotime() - start.time
        iteration.dt.list[[paste(
          seed, init.name, algo, step.number, objective
        )]] <- data.table(
          seed, init.name, algo, step.number, objective, elapsed.time, time=current.time, summary.dt)
        new.obj <- summary.dt.list$subtrain[[paste0(objective,".diffs")]]
        improvement <- obj.sign*(prev.obj-new.obj)
        cat(sprintf(
          "seed=%d init=%s algo=%s step=%d %s %f->%f\n",
          seed, init.name, algo, step.number, objective, prev.obj, new.obj))
        1e-5 < improvement
      }){
        ##while(step.number<2){
        pred.vec <- X.subtrain %*% weight.vec
        aum.list <- aum::aum(diffs.list$subtrain, pred.vec)
        pred.grad.vec <- rowMeans(aum.list$derivative_mat)
        direction.vec <- neg.t.X.subtrain %*% pred.grad.vec
        take.step <- function(s){
          weight.vec+s*direction.vec
        }
        ptm <- proc.time() # timer
        grid.result <- NULL
        exact.result <- NULL
        if (algo == "grid") {
          step.grid <- 10^seq(-9, 0)
          grid.dt <- data.table(step.size=step.grid)[, {
            step.weight <- take.step(step.size)
            grid.aum <- aum_auc(diffs.list$subtrain, X.subtrain %*% step.weight)
            with(grid.aum, data.table(auc, aum))
          }, by=step.size]
          grid.result <- grid.dt[, .(search="grid", step.size, auc, aum)]
        } else if (algo == "exactL" || algo == "exactQ") {
          LS=aum::aum_line_search(
            diffs.list$subtrain, X.subtrain, weight.vec, maxIterations=max.iterations)
          exact.result <- LS$line_search_result[, .(search="exact", step.size, auc, aum)]
        } else if (algo == "hybrid") {
          LS=aum::aum_line_search(
            diffs.list$subtrain, X.subtrain, weight.vec, maxIterations=max.iterations)
          exact.result <- LS$line_search_result[, .(search="exact", step.size, auc, aum)]
          search.result <- data.table(LS$line_search_result)
          search.result[, kink := .I/.N]
          best.row <- search.result[which.min(aum)]          
          if (best.row$kink == 1) {
            # if kink == 1, we have chosen the very last step size we looked at.
            # run a grid search where we're at to find a larger step.size
            steps.list <- list()
            for (s in 10^seq(1,5)) {
              step.size <- best.row$step.size * s
              step.weight <- take.step(step.size)
              step.aum <- aum_auc(diffs.list$subtrain, X.subtrain %*% step.weight)
              if (step.aum$aum < best.row$aum) { # TODO AUC check
                step.result <- data.table(search="grid", step.size, auc=step.aum$auc, aum=step.aum$aum)
                steps.list[[paste(s)]] <- step.result
              } else {
                break
              }
            }
            if (length(steps.list) > 0) {
              grid.result <- rbindlist(steps.list)
            }
          }
        }
        elapsed.time <- (proc.time() - ptm)[["elapsed"]] # timer end
        steps.considered <- rbind(
          exact.result,
          grid.result
        )[, step.prop := seq(1, .N)/.N, by=search][]
        #considered.dt.list[[paste(
        #  seed, init.name, algo, objective, step.number
        #)]] <- data.table(
        #  seed, init.name, algo, objective, step.number, steps.considered)
        best.step <- steps.considered[which.min(obj.sign*get(objective))]
        weight.vec <- take.step(best.step$step.size)
        new.aum <- aum::aum(diffs.list$subtrain, X.subtrain %*% weight.vec)
        err.thresh <- data.table(
          new.aum$total_error,key="thresh"
        )[, err_before := fp_before+fn_before][, .(
          thresh=c(thresh[1]-1,thresh[-1]-diff(thresh)/2,thresh[.N]+1),
          err=c(err_before,sum(diffs.list$subtrain$fp_diff))
        )]
        intercept <- err.thresh[which.min(err), thresh]
        step.number <- step.number+1
        prev.obj <- new.obj
      }#step.number
    }#algo/objective
  }#seed/init.name
  list(
    sets=data.table(
      do.call(rbind, iteration.dt.list),
      testFold.path, data.name, cv.type, test.fold))
  #steps=data.table(
  #  rbindlist(considered.dt.list),
  #  data.name, cv.type, test.fold))
}

# Set of Jobs to run
# aum.type is FPR/FNR or FP/FN count
# init.name is the starting weight matrix
args.dt <- data.table::CJ(
  testFold.path=datasets.by.size$name[1:181],#testFold.vec,
  aum.type=c("rate"),#,"count")
  init.name=c("zero"),#, "IntervalRegressionCV")
  seed=c(1, 2, 3, 4)
)

## Run on SLURM.
registry.dir <- "figure-line-grid-search-interactive-registry"
registry.dir <- "figure-line-grid-search-interactive-registry-6"#4 datasets w hybrid A,B (1.2mb)
registry.dir <- "figure-line-grid-search-interactive-registry-7"#23 datasets (1.6mb)
registry.dir <- "figure-line-grid-search-interactive-registry-8"#70 datasets (20mb)
registry.dir <- "figure-line-grid-search-interactive-registry-9"#109 datasets (28mb)
registry.dir <- "figure-line-grid-search-interactive-registry-10"#[1:109] datasets w/ init.name=c("zero", "IntervalRegressionCV")
registry.dir <- "figure-line-grid-search-interactive-registry-11"#[1:181]
registry.dir <- "figure-line-grid-search-interactive-registry-12"# new hybridC
registry.dir <- "figure-line-grid-search-interactive-registry-13"# better params for hybridB (it's like hybridC now but searches more grid points)
registry.dir <- "figure-line-grid-search-interactive-registry-15"# testing hybridD
registry.dir <- "figure-line-grid-search-interactive-registry-16"# maybe final run?
registry.dir <- "figure-line-grid-search-interactive-registry-17"# many-seeds

if (FALSE) {
  reg=batchtools::loadRegistry(registry.dir, writeable = TRUE)
  #batchtools::clearRegistry(reg)
  batchtools::getStatus(reg=reg)
  batchtools::findExpired(reg=reg)
  status.dt <- batchtools::getJobStatus(reg=reg)
  status.dt[!is.na(error)]
  status.dt[!is.na(done)]
}

#analyze.
if(FALSE){
  done.ids <- status.dt[is.na(error), job.id]
  for(done.i in done.ids){
    job.id <- done.ids[[done.i]]
    args.row <- args.dt[job.id]
    ls.dir <- file.path(args.row$testFold.path, "line_search", "sets")
    dir.create(ls.dir, showWarnings = FALSE, recursive = TRUE)
    ls.csv <- file.path(ls.dir, paste0(args.row$aum.type, ".csv"))
    if(!file.exists(ls.csv)){
      cat(sprintf("%4d / %4d %s\n", done.i, length(done.ids), ls.csv))
      res <- batchtools::loadResult(job.id)
      best.steps <- res$steps[
        , .SD[which.min(aum)], by=.(
          seed,init.name,algo,objective,step.number
        )][,.(seed,init.name,algo,objective,step.number=step.number+1,search)]
      join.dt <- best.steps[res$sets, on=.(
        seed,init.name,algo,objective,step.number
      )]
      join.dt[is.na(search), table(step.number)]
      fwrite(join.dt, ls.csv)
    }  
  }
}

# args.dt[5:8]   CTCF_TDH_ENCODE 2407
# args.dt[13:16] H3K27ac_TDH_some 798
# args.dt[17:20] H3K27me3_RL_cancer 592
# args.dt[21:24] H3K27me3_TDH_some 296
# args.dt[29:32] H3K36me3_TDH_ENCODE 377
# args.dt[37:40] H3K36me3_TDH_other 554
# args.dt[c(13:16,21:24,29:32,37:40,17:20)]

if(FALSE){
  unlink(registry.dir, recursive=TRUE)
}
# CREATE REGISTRY AND RUN JOBS
reg <- batchtools::makeRegistry(file.dir=registry.dir)
#parallel.job.count <- 8
reg$cluster.functions <- makeClusterFunctionsMulticore()
# sample random test folds
#batchtools::batchMap(OneBatch, args=args.dt[sample(1:nrow(args.dt), 5)], reg=reg)
batchtools::batchMap(OneBatch, args=args.dt, reg=reg)
job.table <- batchtools::getJobTable(reg=reg)
chunks <- data.frame(job.table,chunk=job.table$job.id)
#chunks <- data.frame(job.table,chunk=(job.table$job.id%%parallel.job.count)+1)
#chunks <- data.frame(job.table, chunk=1)
options(batchtools.verbose=TRUE, batchtools.progress=TRUE)
runJobs <- function() {
  ptm <- proc.time()
  batchtools::submitJobs(chunks, resources=list(
    walltime = 24 * 60 * 60,#seconds
    memory = 5000,#megabytes per cpu
    #max.concurrent.jobs = parallel.job.count,
    ncpus=1,  #>1 for multicore/parallel jobs.
    ntasks=1, #>1 for MPI jobs.
    chunks.as.arrayjobs=FALSE), reg=reg)
  total.time <- (proc.time() - ptm)[["elapsed"]]
  total.time
}
cat(sprintf("Finished running jobs in %f minutes\n", runJobs() / 60))

batchtools::getStatus(reg=reg)
status.dt <- batchtools::getJobStatus(reg=reg)
status.dt[!is.na(error)]
status.dt[!is.na(done)]


ggplot()+
  facet_grid(init.name + objective ~ ., labeller=label_both, scales="free")+
  geom_point(aes(
    auc, algo),
    data=compare.obj.dt)+
  scale_x_continuous(
    "Best validation AUC")


# jadon tests

# load the first test and graph auc by each algorithm
if(FALSE) {
  result.one <- loadResult(1, reg)
  ggplot(result.one$sets[objective=="aum"]) +
    geom_line(aes(x=step.number, y=aum, color=algo, linetype=as.factor(set))) +
    facet_grid(init.name ~ algo, scales="free") +
    scale_x_log10() +
    scale_y_log10()
}

# load all results and build one big data table
result.sets.list <- list()
status.dt <- batchtools::getJobStatus(reg=reg)
completed.jobs <- status.dt[is.na(error)]$job.id
for (result.id in completed.jobs) {
  # ensure this job is done
  if (!is.na(status.dt[job.id==result.id]$done)) {
    r <- batchtools::loadResult(result.id, reg)
    r$sets[,result.id:=result.id]
    result.sets.list[[result.id]] <- r$sets
    r <- NULL
  }
}
result.sets <- do.call(rbind, result.sets.list)
result.sets.list <- NULL

algo.time.by.dataset <- data.table(result.sets[init.name=="zero"][objective=="aum"][set=="validation"] %>%
                                     group_by(result.id, algo, testFold.path) %>%
                                     reframe(total.time = sum(elapsed.time)))
colnames(algo.time.by.dataset)[colnames(algo.time.by.dataset) == "testFold.path"] <- "name"
results.with.dataset.size <- merge(algo.time.by.dataset, datasets.by.size, on=.(name))

algo.time.by.dataset.with.inits <- data.table(result.sets[objective=="aum"][set=="validation"] %>%
                                                group_by(result.id, algo, testFold.path, init.name) %>%
                                                reframe(total.time = sum(elapsed.time)))
colnames(algo.time.by.dataset.with.inits)[colnames(algo.time.by.dataset.with.inits) == "testFold.path"] <- "name"
results.with.dataset.size.and.init <- merge(algo.time.by.dataset.with.inits, datasets.by.size, on=.(name))


# name for the folder for the images below to go in
experiment.name <- "many-seeds"
dir.create(file.path(experiment.name))


# palette for everything below
cbPalette <- c("#E69F00", "#56B4E9", "#009E73", "#DA72B2", "#D55E00", "#F2D0A4")

# plot elapsed time per step of gradient descent for each algo/dataset
ggplot(result.sets[objective=="aum"][set=="validation"]) +
  geom_point(aes(x=step.number, y=elapsed.time, color=algo, linetype=as.factor(set))) +
  facet_grid(init.name ~ result.id, scale="free") +
  #scale_x_log10() +
  scale_y_log10() +
  scale_colour_manual(values=cbPalette)
ggsave(paste(sep="/", experiment.name, "elapsed.time.png"), width=1920*3, height=1080*3, units="px")

ggplot(result.sets[init.name=="zero"][objective=="aum"][set=="validation"],
       aes(x=step.number, y=elapsed.time, color=algo, linetype=as.factor(set))) +
  geom_point() +
  geom_smooth() +
  facet_wrap(vars(result.id), scale="free") +
  #facet_grid(init.name, scale="free") +
  #scale_x_log10() +
  scale_y_log10() +
  scale_colour_manual(values=cbPalette) +
  scale_fill_manual(values=cbPalette)
ggsave(paste(sep="/", experiment.name, "elapsed.time2.png"), width=1920*3, height=1080*3, units="px")

# histogram version of the above
ggplot(result.sets[init.name=="zero"][objective=="aum"][set=="validation"]) +
  geom_histogram(aes(x=elapsed.time, fill=algo), binwidth = 0.05, color="black") +
  scale_x_log10() +
  scale_y_log10() +
  scale_colour_manual(values=cbPalette) +
  scale_fill_manual(values=cbPalette) +
  ggtitle("Time per step of Gradient Descent") +
  ylab("Count") +
  xlab("Time (seconds)")
ggsave(paste(sep="/", experiment.name, "elapsed.time3.png"), width=1920*3, height=1080*3, units="px")

ggplot(result.sets[init.name=="zero"][objective=="aum"][set=="validation"]) +
  geom_boxplot(aes(x=algo, y=elapsed.time, fill=algo),color="black") +
  #scale_x_log10() +
  scale_y_log10() +
  scale_colour_manual(values=cbPalette) +
  scale_fill_manual(values=cbPalette) +
  ggtitle("Time per step of Gradient Descent") +
  ylab("Time (seconds)") +
  xlab("Algorithm")
ggsave(paste(sep="/", experiment.name, "elapsed.time4.png"), width=1920*3, height=1080*3, units="px")

ggplot(result.sets[init.name=="zero"][objective=="aum"][set=="validation"]) +
  geom_violin(aes(x=algo, y=elapsed.time, fill=algo),color="black") +
  #scale_x_log10() +
  scale_y_log10() +
  scale_colour_manual(values=cbPalette) +
  scale_fill_manual(values=cbPalette) +
  ggtitle("Time per step of Gradient Descent") +
  ylab("Time (seconds)") +
  xlab("Algorithm")
ggsave(paste(sep="/", experiment.name, "elapsed.time5.png"), width=1920*3, height=1080*3, units="px")


# plot aum for each dataset
ggplot(result.sets[init.name=="zero"][objective=="aum"][set=="validation"]) +
  geom_line(aes(x=step.number, y=aum, color=algo, linetype=as.factor(set))) +
  facet_wrap(vars(result.id), scale="free") +
  scale_x_log10() +
  scale_y_log10() +
  scale_colour_manual(values=cbPalette)
ggsave(paste(sep="/", experiment.name, "aum.png"), width=1920*3, height=1080*3, units="px")


ggplot(result.sets[init.name=="zero"][objective=="aum"][set=="validation"]) +
  geom_line(aes(x=step.number, y=auc, color=algo, linetype=as.factor(set))) +
  facet_wrap(vars(result.id), scale="free") +
  scale_x_log10() +
  scale_y_log10() +
  scale_colour_manual(values=cbPalette)
ggsave(paste(sep="/", experiment.name, "auc.png"), width=1920*3, height=1080*3, units="px")

# total time by algo (bar chart)
result.sets[init.name=="zero"][objective=="aum"][set=="validation"] %>%
  group_by(result.id, algo) %>%
  summarize(total.time = sum(elapsed.time)) %>%
  ggplot() +
  geom_col(aes(x=algo, y=total.time, fill=algo)) +
  #scale_y_log10() +
  geom_text(aes(x=algo, y=total.time, label=round(total.time,digits=1)), position=position_dodge(width=0.9), vjust=-0.25) +
  facet_grid(. ~ result.id) +
  scale_colour_manual(values=cbPalette)
ggsave(paste(sep="/", experiment.name, "total.time.png"), width=1920*3, height=1080*3, units="px")

ggplot(result.sets[init.name=="zero"][objective=="aum"][set=="validation"][result.id %in% c(1:8, 16:19)]) +
  geom_line(aes(x=step.number, y=aum, color=algo),size=1.1) +
  #geom_smooth(aes(x=time, y=aum, color=algo, fill=algo)) +
  facet_grid(data.name ~ test.fold, scale="free", labeller = label_both) +
  scale_x_log10() +
  scale_y_log10() +
  scale_colour_manual(values=cbPalette) +
  scale_fill_manual(values=cbPalette) +
  ggtitle("Validation AUM over steps of gradient descent for select datasets") +
  #xlab("timestamp") +
  ylab("AUM")
ggsave(paste(sep="/", experiment.name, "aum.over.time.png"), width=1920*3, height=1080*3, units="px")

ggplot(result.sets[init.name=="zero"][objective=="aum"][set=="validation"][result.id %in% c(1:8, 16:19)]) +
  geom_line(aes(x=step.number, y=aum, color=algo),size=1.1) +
  #geom_smooth(aes(x=time, y=aum, color=algo, fill=algo)) +
  facet_grid(data.name ~ test.fold, scale="free", labeller = label_both) +
  scale_x_log10() +
  scale_y_log10() +
  scale_colour_manual(values=cbPalette) +
  scale_fill_manual(values=cbPalette) +
  ggtitle("Validation AUM over steps of gradient descent for select datasets") +
  xlab("step number") +
  ylab("AUM")
ggsave(paste(sep="/", experiment.name, "aum.over.time2.png"), width=1920*2, height=1080*2, units="px")

ggplot(result.sets[init.name=="zero"][objective=="aum"][set=="validation"][result.id %in% c(1:8, 16:19)]) +
  geom_line(aes(x=step.number, y=auc, color=algo),size=1.1) +
  #geom_smooth(aes(x=time, y=aum, color=algo, fill=algo)) +
  facet_grid(data.name ~ test.fold, scale="free", labeller = label_both) +
  scale_x_log10() +
  scale_y_log10() +
  scale_colour_manual(values=cbPalette) +
  scale_fill_manual(values=cbPalette) +
  ggtitle("Validation AUC over steps of gradient descent for select datasets") +
  xlab("step number") +
  ylab("AUC")
ggsave(paste(sep="/", experiment.name, "auc.over.time2.png"), width=1920*2, height=1080*2, units="px")


# boxplot total time by algo
result.sets[objective=="aum"][set=="validation"] %>%
  group_by(result.id, algo, init.name) %>%
  reframe(total.time = sum(elapsed.time)) %>%
  ggplot() +
  #geom_violin(aes(x=algo, y=total.time, fill=algo)) +
  geom_boxplot(aes(x=algo, y=total.time, fill=algo)) +
  scale_y_log10() +
  #geom_text(aes(x=algo, y=total.time, label=round(total.time,digits=3)), position=position_dodge(width=0.9), vjust=-0.25) +
  facet_grid(. ~ init.name) +
  scale_colour_manual(values=cbPalette) +
  scale_fill_manual(values=cbPalette) + 
  xlab("Algorithm") +
  ylab("Total time (seconds)") +
  ggtitle("Total time across datasets")
ggsave(paste(sep="/", experiment.name, "total.time.across.datasets.png"), width=1920*3, height=1080*3, units="px")

result.sets[objective=="aum"][set=="validation"] %>%
  group_by(result.id, algo, init.name) %>%
  reframe(total.time = sum(elapsed.time)) %>%
  ggplot() +
  geom_violin(aes(x=algo, y=total.time, fill=algo)) +
  #geom_boxplot(aes(x=algo, y=total.time, fill=algo)) +
  scale_y_log10() +
  #geom_text(aes(x=algo, y=total.time, label=round(total.time,digits=3)), position=position_dodge(width=0.9), vjust=-0.25) +
  facet_grid(. ~ init.name) +
  scale_colour_manual(values=cbPalette) +
  scale_fill_manual(values=cbPalette) + 
  xlab("Algorithm") +
  ylab("Total time (seconds)") +
  ggtitle("Total time across datasets")
ggsave(paste(sep="/", experiment.name, "total.time.across.datasets2.png"), width=1920*3, height=1080*3, units="px")

result.sets[objective=="aum"][init.name=="zero"][set=="validation"] %>%
  group_by(result.id, algo, init.name) %>%
  reframe(total.time = sum(elapsed.time)) %>%
  ggplot() +
  #geom_violin(aes(x=algo, y=total.time, fill=algo)) +
  geom_boxplot(aes(x=algo, y=total.time, fill=algo)) +
  scale_y_log10() +
  #geom_text(aes(x=algo, y=total.time, label=round(total.time,digits=3)), position=position_dodge(width=0.9), vjust=-0.25) +
  #facet_grid(. ~ init.name) +
  scale_colour_manual(values=cbPalette) +
  scale_fill_manual(values=cbPalette) + 
  xlab("Algorithm") +
  ylab("Total time (seconds)") +
  ggtitle("Total time across datasets")
ggsave(paste(sep="/", experiment.name, "total.time.across.datasets3.png"), width=1920*2, height=1080*2, units="px")


results.with.dataset.size %>%
  ggplot() +
  geom_line(aes(x=size, y=total.time, color=algo)) +
  scale_y_log10() +
  scale_x_log10() +
  scale_colour_manual(values=cbPalette)
ggsave(paste(sep="/", experiment.name, "size.affects.time.png"), width=1920*2, height=1080*2, units="px")

results.with.dataset.size %>%
  #group_by(algo, s=signif(size, 3)) %>%
  #reframe(t=mean(total.time)) %>%
  ggplot(aes(x=size, y=total.time, color=algo, fill=algo)) +
  geom_point() +
  geom_smooth(level=0.70,span=0.6) +
  scale_y_log10() +
  scale_x_log10() +
  scale_colour_manual(values=cbPalette) +
  scale_fill_manual(values=cbPalette) +
  xlab("Size of Dataset (bytes)") +
  ylab("Total time (seconds)")
ggtitle("Dataset size vs. Algorithm time")
ggsave(paste(sep="/", experiment.name, "size.affects.time2.png"), width=1920*3, height=1080*3, units="px")

results.with.dataset.size.and.init %>%
  #group_by(algo, s=signif(size, 3)) %>%
  #reframe(t=mean(total.time)) %>%
  ggplot(aes(x=size, y=total.time, color=algo, fill=algo)) +
  geom_point(size=0.5) +
  geom_smooth(level=0.95)+#geom_smooth(level=0.70,span=0.6) +
  scale_y_log10() +
  scale_x_log10() +
  scale_colour_manual(values=cbPalette) +
  scale_fill_manual(values=cbPalette) +
  facet_grid(init.name ~ .) +
  xlab("Size of Dataset (bytes)") +
  ylab("Total time (seconds)") +
  ggtitle("Dataset size vs. Algorithm time")
ggsave(paste(sep="/", experiment.name, "size.affects.time3.png"), width=1920*3, height=1080*3, units="px")

results.with.dataset.size %>%
  #group_by(algo, s=signif(size, 3)) %>%
  #reframe(t=mean(total.time)) %>%
  ggplot(aes(x=observations, y=total.time, color=algo, fill=algo)) +
  geom_point() +
  geom_smooth(span=1) +
  scale_y_log10() +
  scale_x_log10() +
  scale_colour_manual(values=cbPalette) +
  scale_fill_manual(values=cbPalette) +
  xlab("# of observations") +
  ylab("Total time (seconds)") +
  ggtitle("Dataset size vs. Algorithm time")
ggsave(paste(sep="/", experiment.name, "size.affects.time4.png"), width=1920*2, height=1080*2, units="px")

rfac <- 2
results.with.dataset.size.and.init[, N := 10^(round(log10(size)*rfac)/rfac)]

results.with.dataset.size.and.init[,data.table(min=min(total.time),max=max(total.time),mean=mean(total.time)), by=.(algo, N)] %>%
  #group_by(algo, s=signif(size, 3)) %>%
  #reframe(t=mean(total.time)) %>%
  ggplot() +
  geom_ribbon(aes(x=N, ymin=min, ymax=max, fill=algo), alpha=0.10) +
  geom_line(aes(x=N, y=mean, color=algo), size=0.8) +
  geom_point(aes(x=N, y=max, color=algo), size=0.7, alpha=0.10) +
  geom_point(aes(x=N, y=min, color=algo), size=0.7, alpha=0.10) +
  geom_point(aes(x=N, y=mean, color=algo), size=1.2) +
  #geom_smooth(level=0.95)+#geom_smooth(level=0.70,span=0.6) +
  scale_y_log10() +
  scale_x_log10() +
  scale_colour_manual(values=cbPalette) +
  scale_fill_manual(values=cbPalette) +
  #facet_grid(init.name ~ .) +
  xlab("B = number of breakpoints in error functions") +
  ylab("Total time (seconds)") + theme_bw()
#ggtitle("Dataset size vs. Algorithm time")
ggsave(paste(sep="/", experiment.name, "size.affects.time5.png"), width=1920*0.75, height=1080*0.75, units="px")

result.sets[init.name=="zero"][objective=="aum"][set=="validation"] %>%
  group_by(result.id, algo) %>%
  summarize(total.time = sum(elapsed.time)) %>%
  ggplot() +
  geom_col(aes(x=algo, y=total.time, fill=algo)) +
  #scale_y_log10() +
  geom_text(aes(x=algo, y=total.time, label=round(total.time,digits=1)), position=position_dodge(width=0.9), vjust=-0.25) +
  facet_grid(. ~ result.id) +
  scale_colour_manual(values=cbPalette)
ggsave(paste(sep="/", experiment.name, "total.time.png"), width=1920*3, height=1080*3, units="px")

result.sets[init.name=="zero"][objective=="aum"][set=="validation"] %>%
  group_by(result.id, algo) %>%
  summarize(total.time = sum(elapsed.time)) %>%
  ggplot() +
  geom_vline(data=result.sets[init.name=="zero"][objective=="aum"][set=="validation"] %>%
               group_by(data.name) %>%
               summarize(total.time = sum(elapsed.time), max.id = max(result.id)),
             aes(xintercept=max.id+0.5),color="grey") +
  geom_point(aes(x=result.id, y=total.time, color=algo),size=1.3) +
  #geom_smooth(aes(x=result.id, y=total.time, color=algo,fill=algo)) +
  #geom_col(aes(x=result.id, y=total.time, fill=algo)) +
  #geom_segment(aes(x=result.id,xend=result.id,y=0,yend=total.time,color=algo)) +
  scale_y_log10() +
  scale_colour_manual(values=cbPalette) +
  scale_fill_manual(values=cbPalette) +
  xlab("Fold/Job ID") +
  ylab("Total time (seconds)") +
  ggtitle("Total time for every dataset fold")
ggsave(paste(sep="/", experiment.name, "total.time2.png"), width=1920*1.5, height=1080*1.5, units="px")

selected.datasets <- c("H3K9me3_TDH_BP", "ATAC_JV_adipose", "H3K27ac-H3K4me3_TDHAM_BP", "detailed")
selected.datasets <- c("H3K9me3_TDH_BP", "detailed")

(dataset.labels <- map(selected.datasets, function(x) {
  size <- mean(datasets.by.size[data.name==x]$observations)
  rounded.size <- round(10^(round(log10(size)*2)/2))
  paste0(x, " (n≃",rounded.size,")")
  paste0(x, " (n=",size,")")
  paste0("B=",round(size))
}))


result.sets[data.name %in% selected.datasets] %>%
  group_by(result.id, algo, data.name, seed) %>%
  reframe(total.time = sum(elapsed.time)) %>%
  ggplot() +
  geom_boxplot(aes(x=total.time, y=factor(algo, levels=c("hybrid","exactL","exactQ","grid")), fill=algo), show.legend = FALSE) +
  facet_wrap(.~factor(data.name, levels=selected.datasets, labels=dataset.labels), scales = "free") +
  scale_x_log10() +
  scale_colour_manual(values=cbPalette) +
  scale_fill_manual(values=cbPalette) +
  ylab("Line Search Algorithm") +
  xlab("Total time (seconds)") +
  theme_bw()
#ggtitle("Time for selected datasets")
ggsave(paste(sep="/", experiment.name, "boxplot.datasets.png"), width=1920*0.75, height=1080*0.75, units="px")

